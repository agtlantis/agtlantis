/**
 * AI Simulated User E2E Test Example
 *
 * Demonstrates AI-simulated user testing with @agtlantis/eval.
 *
 * Features demonstrated:
 * - `aiUser()` factory function for AI-generated user inputs
 * - `turns` option for repeating the same input source multiple times
 * - `turns: Infinity` for continuous AI-driven conversation until termination
 * - Different AI customer personas (friendly, rushed, unhappy)
 * - Dynamic persona that changes behavior based on turn count
 *
 * Usage:
 * ```bash
 * # 1. Create .env file in packages/agent-eval
 * cd packages/agent-eval
 * cp .env.example .env
 * # Set OPENAI_API_KEY in .env
 *
 * # 2. Run from project root
 * pnpm --filter @agtlantis/eval example:ai-user
 * ```
 */

import { createOpenAIProvider } from '@agtlantis/core'
import {
  createJudge,
  defaultJudgePrompt,
  accuracy,
  relevance,
  executeMultiTurnTestCase,
  aiUser,
  type MultiTurnTestCase,
  type MultiTurnExecuteContext,
  type ConversationContext,
} from '../src/index'
import {
  createBookingAgent,
  type BookingInput,
  type BookingOutput,
  type ConversationMessage,
} from './multi-turn-agent/agent'

// ============================================================================
// Helper: Build conversation history from test framework context
// ============================================================================

/**
 * Converts test framework's conversation context to BookingInput format.
 * This enables stateless agents to maintain multi-turn conversation context.
 */
function buildInputWithHistory(
  message: string,
  ctx: ConversationContext<BookingInput, BookingOutput>
): BookingInput {
  const conversationHistory: ConversationMessage[] = []

  for (const turn of ctx.history) {
    // Add user message
    conversationHistory.push({
      role: 'user',
      content: turn.input.message,
    })
    // Add assistant response (extract reply from output)
    if (turn.output?.reply) {
      conversationHistory.push({
        role: 'assistant',
        content: turn.output.reply,
      })
    }
  }

  return {
    message,
    conversationHistory,
  }
}

/**
 * Format conversation history for the AI user's LLM prompt.
 * Provides a human-readable format specific to the booking domain.
 */
function formatBookingHistory(ctx: ConversationContext<BookingInput, BookingOutput>): string {
  return ctx.history
    .map((h) => {
      const input = h.input as BookingInput
      const output = h.output as BookingOutput
      let turn = `ê³ ê°: ${input.message}\nì§ì›: ${output.reply}`
      if (output.booking) {
        turn += `\n[ì˜ˆì•½ ìƒíƒœ: ${output.booking.status}]`
      }
      return turn
    })
    .join('\n---\n')
}

// ============================================================================
// 1. Environment Setup
// ============================================================================

const OPENAI_API_KEY = process.env.OPENAI_API_KEY

if (!OPENAI_API_KEY) {
  console.error('âŒ OPENAI_API_KEY environment variable is not set.')
  console.error('   Create a .env file with OPENAI_API_KEY=sk-xxx')
  console.error('   Example: echo "OPENAI_API_KEY=sk-xxx" > .env')
  process.exit(1)
}

// ============================================================================
// 2. Create Provider and Agent
// ============================================================================

const provider = createOpenAIProvider({
  apiKey: OPENAI_API_KEY,
}).withDefaultModel('gpt-5-nano') // Cost-effective model

const bookingAgent = createBookingAgent(provider)

// ============================================================================
// 3. Create Judge
// ============================================================================

const judge = createJudge({
  provider,
  prompt: defaultJudgePrompt,
  criteria: [
    accuracy({ weight: 2 }),
    relevance(),
    {
      id: 'conversation-naturalness',
      name: 'ëŒ€í™” ìì—°ìŠ¤ëŸ¬ì›€',
      description: 'AI ì‚¬ìš©ìì™€ Agent ê°„ì˜ ëŒ€í™”ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì§„í–‰ë˜ì—ˆëŠ”ê°€',
      weight: 2,
    },
    {
      id: 'booking-completeness',
      name: 'ì˜ˆì•½ ì™„ì „ì„±',
      description: 'ëª¨ë“  í•„ìˆ˜ ì •ë³´(ë‚ ì§œ, ì‹œê°„, ì¸ì›, ì´ë¦„, ì „í™”ë²ˆí˜¸)ê°€ ìˆ˜ì§‘ë˜ì—ˆëŠ”ê°€',
      weight: 2,
    },
  ],
  passThreshold: 70,
})

// ============================================================================
// 4. AI User Personas
// ============================================================================

/**
 * Friendly Customer Persona
 *
 * A polite and cooperative customer who provides information clearly
 * and responds positively to the agent's questions.
 */
const friendlyCustomerSystemPrompt = `ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  í˜‘ì¡°ì ì¸ ê³ ê°ì…ë‹ˆë‹¤.

í–‰ë™ ì§€ì¹¨:
- ì§ì›ì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤
- ì˜ˆì˜ ë°”ë¥´ê³  ê¸ì •ì ì¸ í†¤ì„ ìœ ì§€í•©ë‹ˆë‹¤
- í•„ìš”í•œ ì •ë³´(ë‚ ì§œ, ì‹œê°„, ì¸ì›, ì´ë¦„, ì „í™”ë²ˆí˜¸)ë¥¼ í•œë‘ ê°œì”© ìì—°ìŠ¤ëŸ½ê²Œ ì œê³µí•©ë‹ˆë‹¤
- ì˜ˆì•½ì´ ì§„í–‰ ì¤‘ì´ë©´ í™•ì •ì„ ìš”ì²­í•©ë‹ˆë‹¤

ì‘ë‹µ í˜•ì‹:
- ë°˜ë“œì‹œ ê³ ê°ì˜ ë§ë§Œ ì¶œë ¥í•˜ì„¸ìš”
- ë”°ì˜´í‘œë‚˜ "ê³ ê°:" ê°™ì€ ì ‘ë‘ì‚¬ ì—†ì´ ìˆœìˆ˜í•œ ëŒ€í™”ë¬¸ë§Œ ì‘ì„±í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”`

/**
 * Rushed Customer Persona
 *
 * An impatient customer who wants quick service
 * and provides information efficiently.
 */
const rushedCustomerSystemPrompt = `ë‹¹ì‹ ì€ ë°”ì˜ê³  ê¸‰í•œ ê³ ê°ì…ë‹ˆë‹¤.

í–‰ë™ ì§€ì¹¨:
- ë¹ ë¥¸ ì˜ˆì•½ì„ ì›í•©ë‹ˆë‹¤
- ê°€ëŠ¥í•˜ë©´ ì—¬ëŸ¬ ì •ë³´ë¥¼ í•œ ë²ˆì— ì œê³µí•˜ë ¤ê³  í•©ë‹ˆë‹¤
- ì§§ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤
- ë¶ˆí•„ìš”í•œ ëŒ€í™”ëŠ” ì¤„ì´ë ¤ í•©ë‹ˆë‹¤
- ì˜ˆì•½ì´ ê±°ì˜ ì™„ë£Œë˜ë©´ ë¹¨ë¦¬ í™•ì •í•´ë‹¬ë¼ê³  ìš”ì²­í•©ë‹ˆë‹¤

ì‘ë‹µ í˜•ì‹:
- ë°˜ë“œì‹œ ê³ ê°ì˜ ë§ë§Œ ì¶œë ¥í•˜ì„¸ìš”
- ë”°ì˜´í‘œë‚˜ ì ‘ë‘ì‚¬ ì—†ì´ ìˆœìˆ˜í•œ ëŒ€í™”ë¬¸ë§Œ ì‘ì„±í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”`

/**
 * Unhappy Customer Persona
 *
 * A dissatisfied customer who has concerns but eventually
 * provides the needed information.
 */
const unhappyCustomerSystemPrompt = `ë‹¹ì‹ ì€ ì•½ê°„ ë¶ˆë§Œì¡±ìŠ¤ëŸ¬ìš´ ê³ ê°ì…ë‹ˆë‹¤.

í–‰ë™ ì§€ì¹¨:
- ì²˜ìŒì—ëŠ” ë¶ˆí‰í•˜ê±°ë‚˜ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤ (ì˜ˆ: "ì €ë²ˆì— ì˜ˆì•½ì´ ì œëŒ€ë¡œ ì•ˆ ëëŠ”ë°...")
- í•˜ì§€ë§Œ ê²°êµ­ í•„ìš”í•œ ì •ë³´ëŠ” ì œê³µí•©ë‹ˆë‹¤
- ì•½ê°„ ê¹Œë‹¤ë¡­ê²Œ êµ´ì§€ë§Œ ë¬´ë¡€í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤
- íŠ¹ë³„ ìš”ì²­(ì°½ê°€ ìë¦¬, ì¡°ìš©í•œ ìë¦¬ ë“±)ì„ ì¶”ê°€í•©ë‹ˆë‹¤
- ì˜ˆì•½ í™•ì • ì „ í™•ì¸ì„ í•œ ë²ˆ ë” ìš”ì²­í•©ë‹ˆë‹¤

ì‘ë‹µ í˜•ì‹:
- ë°˜ë“œì‹œ ê³ ê°ì˜ ë§ë§Œ ì¶œë ¥í•˜ì„¸ìš”
- ë”°ì˜´í‘œë‚˜ ì ‘ë‘ì‚¬ ì—†ì´ ìˆœìˆ˜í•œ ëŒ€í™”ë¬¸ë§Œ ì‘ì„±í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”`

// ============================================================================
// 5. Multi-turn Test Cases with AI Users
// ============================================================================

/**
 * Test Case 1: Friendly Customer - AI Driven Booking
 *
 * Uses aiUser() with `turns: Infinity` to generate all follow-up inputs
 * with a friendly persona until the booking is confirmed.
 *
 * NOTE: Before `turns` option, we had to define aiUser() 5+ times.
 * Now a single entry with `turns: Infinity` handles unlimited follow-ups!
 */
const friendlyCustomerTest: MultiTurnTestCase<BookingInput, BookingOutput> = {
  id: 'ai-friendly-customer',
  description: 'AI simulates a friendly customer completing a booking',
  tags: ['ai-user', 'friendly', 'happy-path'],

  // First turn: User initiates booking
  input: { message: 'ì•ˆë…•í•˜ì„¸ìš”, ì˜ˆì•½í•˜ê³  ì‹¶ì€ë°ìš”.' },

  multiTurn: {
    // Single aiUser() with turns: Infinity handles all follow-ups
    followUpInputs: [
      {
        input: aiUser<BookingInput, BookingOutput>({
          provider,
          systemPrompt: friendlyCustomerSystemPrompt,
          formatHistory: formatBookingHistory,
          buildInput: (response, ctx) => buildInputWithHistory(response, ctx),
        }),
        description: 'AI friendly customer',
        turns: Infinity, // Continue until termination condition is met
      },
    ],

    terminateWhen: [
      { type: 'fieldValue', fieldPath: 'booking.status', expectedValue: 'confirmed' },
    ],

    maxTurns: 5, // Reduced from 8 for faster feedback
    onConditionMet: 'pass',
    onMaxTurnsReached: 'fail',
  },
}

/**
 * Test Case 2: Rushed Customer - Quick Booking
 *
 * Uses aiUser() with a rushed persona. With `turns: Infinity`,
 * the AI continues until booking is confirmed or maxTurns is reached.
 */
const rushedCustomerTest: MultiTurnTestCase<BookingInput, BookingOutput> = {
  id: 'ai-rushed-customer',
  description: 'AI simulates a rushed customer wanting quick service',
  tags: ['ai-user', 'rushed', 'efficiency'],

  // First turn: Rushed request
  input: { message: 'ì˜ˆì•½ ë¹¨ë¦¬ ì¢€ í•´ì£¼ì„¸ìš”.' },

  multiTurn: {
    followUpInputs: [
      {
        input: aiUser<BookingInput, BookingOutput>({
          provider,
          systemPrompt: rushedCustomerSystemPrompt,
          formatHistory: formatBookingHistory,
          buildInput: (response, ctx) => buildInputWithHistory(response, ctx),
        }),
        description: 'AI rushed customer',
        turns: Infinity,
      },
    ],

    terminateWhen: [
      { type: 'fieldValue', fieldPath: 'booking.status', expectedValue: 'confirmed' },
    ],

    maxTurns: 6,
    onConditionMet: 'pass',
    onMaxTurnsReached: 'fail',
  },
}

/**
 * Test Case 3: Unhappy Customer - Booking with Complaints
 *
 * Uses aiUser() with an unhappy persona. With `turns: Infinity`,
 * allows longer conversations needed for unhappy customers.
 */
const unhappyCustomerTest: MultiTurnTestCase<BookingInput, BookingOutput> = {
  id: 'ai-unhappy-customer',
  description: 'AI simulates an unhappy customer with concerns',
  tags: ['ai-user', 'unhappy', 'edge-case'],

  // First turn: Complaint-laden request
  input: { message: 'ì €ë²ˆì— ì˜ˆì•½ì´ ì¢€ ë¬¸ì œê°€ ìˆì—ˆëŠ”ë°... ë‹¤ì‹œ ì˜ˆì•½í•˜ë ¤ê³ ìš”.' },

  multiTurn: {
    followUpInputs: [
      {
        input: aiUser<BookingInput, BookingOutput>({
          provider,
          systemPrompt: unhappyCustomerSystemPrompt,
          formatHistory: formatBookingHistory,
          buildInput: (response, ctx) => buildInputWithHistory(response, ctx),
        }),
        description: 'AI unhappy customer',
        turns: Infinity,
      },
    ],

    terminateWhen: [
      { type: 'fieldValue', fieldPath: 'booking.status', expectedValue: 'confirmed' },
    ],

    maxTurns: 6, // Reduced from 10 for faster feedback
    onConditionMet: 'pass',
    onMaxTurnsReached: 'fail',
  },
}

/**
 * Test Case 4: Dynamic Persona - Escalating Impatience
 *
 * Uses a dynamic system prompt that changes the AI's behavior
 * based on the conversation turn. With `turns: Infinity`, the
 * single aiUser() definition handles all follow-ups while the
 * dynamic systemPrompt changes behavior automatically.
 */
const dynamicPersonaTest: MultiTurnTestCase<BookingInput, BookingOutput> = {
  id: 'ai-dynamic-persona',
  description: 'AI persona changes from friendly to rushed as turns progress',
  tags: ['ai-user', 'dynamic', 'persona-change'],

  input: { message: 'ì˜ˆì•½ ë¬¸ì˜ë“œë¦½ë‹ˆë‹¤.' },

  multiTurn: {
    followUpInputs: [
      {
        input: aiUser<BookingInput, BookingOutput>({
          provider,
          // Dynamic system prompt based on turn count
          systemPrompt: (ctx) => {
            if (ctx.currentTurn <= 2) {
              return `ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê°ì…ë‹ˆë‹¤. ì°¨ë¶„í•˜ê²Œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ì‘ë‹µ í˜•ì‹: ê³ ê°ì˜ ë§ë§Œ ì¶œë ¥í•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.`
            } else if (ctx.currentTurn <= 4) {
              return `ë‹¹ì‹ ì€ ì•½ê°„ ê¸‰í•´ì§„ ê³ ê°ì…ë‹ˆë‹¤. ë¹ ë¥¸ ì§„í–‰ì„ ì›í•©ë‹ˆë‹¤.
ì‘ë‹µ í˜•ì‹: ê³ ê°ì˜ ë§ë§Œ ì¶œë ¥í•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.`
            } else {
              return `ë‹¹ì‹ ì€ ë§¤ìš° ê¸‰í•œ ê³ ê°ì…ë‹ˆë‹¤. ì¦‰ì‹œ í™•ì •ì„ ì›í•©ë‹ˆë‹¤.
ì‘ë‹µ í˜•ì‹: ê³ ê°ì˜ ë§ë§Œ ì¶œë ¥í•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.`
            }
          },
          formatHistory: formatBookingHistory,
          buildInput: (response, ctx) => buildInputWithHistory(response, ctx),
        }),
        description: 'Dynamic persona (escalating impatience)',
        turns: Infinity, // Dynamic systemPrompt changes behavior each turn
      },
    ],

    terminateWhen: [
      { type: 'fieldValue', fieldPath: 'booking.status', expectedValue: 'confirmed' },
    ],

    maxTurns: 5,
    onConditionMet: 'pass',
    onMaxTurnsReached: 'fail',
  },
}

// Collect all test cases
const testCases: MultiTurnTestCase<BookingInput, BookingOutput>[] = [
  friendlyCustomerTest,
  rushedCustomerTest,
  unhappyCustomerTest,
  dynamicPersonaTest,
]

// ============================================================================
// 6. Execution
// ============================================================================

async function main() {
  console.log('ğŸ¤– AI Simulated User E2E Test')
  console.log('='.repeat(60))
  console.log(`   Test Cases: ${testCases.length}`)
  console.log(`   Model: gpt-5-nano`)
  console.log('')
  console.log('This test demonstrates AI-driven multi-turn conversations')
  console.log('where the AI plays different customer personas.')
  console.log('')

  const executeContext: MultiTurnExecuteContext<BookingInput, BookingOutput> = {
    agent: bookingAgent,
    judge,
    agentDescription: 'A conversational restaurant reservation assistant',
  }

  let passed = 0
  let failed = 0
  let totalScore = 0
  let totalTokens = 0
  let totalLatency = 0

  for (const testCase of testCases) {
    console.log(`\nğŸ“ Running: ${testCase.id}`)
    console.log(`   ${testCase.description}`)
    console.log('-'.repeat(60))

    try {
      const result = await executeMultiTurnTestCase(testCase, executeContext)

      // Display conversation
      console.log('\n   ğŸ’¬ Conversation:')
      for (const turn of result.conversationHistory) {
        console.log(`      Turn ${turn.turn}:`)
        const input = turn.input as BookingInput
        console.log(`        ğŸ§‘ Customer: ${input.message}`)
        const output = turn.output as BookingOutput
        console.log(`        ğŸ¤– Agent: ${output?.reply?.slice(0, 100)}...`)
        if (output?.booking) {
          console.log(`        ğŸ“‹ Status: ${output.booking.status}`)
        }
      }

      // Display result
      console.log('\n   ğŸ“Š Result:')
      console.log(`      Total Turns: ${result.totalTurns}`)
      console.log(`      Termination: ${result.termination.reason}`)
      console.log(`      Score: ${result.overallScore.toFixed(1)}`)
      console.log(`      Passed: ${result.passed ? 'âœ…' : 'âŒ'}`)

      // Display verdicts
      if (result.verdicts.length > 0) {
        console.log('\n   ğŸ“ Verdicts:')
        for (const verdict of result.verdicts) {
          const status = verdict.passed ? 'âœ…' : 'âŒ'
          console.log(`      ${status} ${verdict.criterionId}: ${verdict.score}`)
        }
      }

      // Track stats
      if (result.passed) {
        passed++
      } else {
        failed++
      }
      totalScore += result.overallScore
      totalTokens += result.metrics.tokenUsage.total
      totalLatency += result.metrics.latencyMs

    } catch (error) {
      console.error(`   âŒ Error: ${error}`)
      failed++
    }
  }

  // Summary
  console.log('\n' + '='.repeat(60))
  console.log('ğŸ“Š Summary')
  console.log('='.repeat(60))
  console.log(`   Total Tests: ${testCases.length}`)
  console.log(`   Passed: ${passed} (${Math.round((passed / testCases.length) * 100)}%)`)
  console.log(`   Failed: ${failed}`)
  console.log(`   Average Score: ${(totalScore / testCases.length).toFixed(1)}`)
  console.log(`   Total Tokens: ${totalTokens}`)
  console.log(`   Average Latency: ${(totalLatency / testCases.length).toFixed(0)}ms`)

  console.log('\n' + '='.repeat(60))
  console.log('ğŸ’¡ Key Observations')
  console.log('='.repeat(60))
  console.log(`   â€¢ turns: Infinity allows a single aiUser() to drive entire conversations`)
  console.log(`   â€¢ AI simulated users generate natural, context-aware responses`)
  console.log(`   â€¢ Different personas result in different conversation dynamics`)
  console.log(`   â€¢ Dynamic systemPrompt + turns: Infinity enables evolving behavior`)
  console.log(`   â€¢ Booking completion depends on both agent and AI user behavior`)
}

main().catch(console.error)
